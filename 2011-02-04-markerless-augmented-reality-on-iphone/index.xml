<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2011-02-04-markerless-augmented-reality-on-iphone-rsses on Ghostwriter example</title>
    <link>https://example.com/2011-02-04-markerless-augmented-reality-on-iphone/index.xml</link>
    <description>Recent content in 2011-02-04-markerless-augmented-reality-on-iphone-rsses on Ghostwriter example</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>My Name</copyright>
    <lastBuildDate>Fri, 04 Feb 2011 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.com/2011-02-04-markerless-augmented-reality-on-iphone/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Markerless Augmented Reality on iPhone</title>
      <link>https://example.com/2011-02-04-markerless-augmented-reality-on-iphone/</link>
      <pubDate>Fri, 04 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/2011-02-04-markerless-augmented-reality-on-iphone/</guid>
      <description>

&lt;p&gt;Hello everyone! Today i want to share my results in research of markerless augmented reality. The  main idea - do fast and quality AR without those damn markers and give the ability to use real object as a target.  Markerless augmented reality is very similar to marker-based systems like ARToolkit with one major difference - such technology use real object as a target for augmentation. It can be almost any kind of objects - photos, logos, beer bottle or Cola can.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The common pipeline is very trivial:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Estimate transformation between real-world target and virtual camera.&lt;/li&gt;
&lt;li&gt;Render virtual objects using estimated transformation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The most complex part - is to find a target on video frame. Actually, algorithm you will use depends on the kind of a target. In my today&amp;rsquo;s showcase i use printed image of the graffity pattern. And i will draw the 3d model on the top of this image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;graffiti-300x240.png&#34; alt=&#34;&#34; title=&#34;graffiti&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For target detection i use feature descriptors. At each frame, algorithm detects keypoints (using FAST feature detector), extracts descriptors (using LAZY descriptor) and match them with reference descriptor set (from the image above). Those matches gives us all necessary information to estimate transformation between camera and target. All necessary functions exists in OpenCV. Here is screenshot from working sample running on the iPhone 3Gs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Screenshot-2011.02.04-10.22.36.png&#34; alt=&#34;Markerless augmented reality&#34; title=&#34;Markerless augmented reality&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;facts&#34;&gt;Facts:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Runs at ~10 fps on iPhone 3Gs.&lt;/li&gt;
&lt;li&gt;3rd party libs used: OpenCV, OGRE, Boost.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;further-work&#34;&gt;Further work:&lt;/h2&gt;

&lt;p&gt;There are a lot of things i wish to do:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Achieve real-time (25+fps) on iPhone&lt;/li&gt;
&lt;li&gt;Introduce two-stage algorithm (expensive initialization &amp;lt;-&amp;gt; lightweight tracking) to get significant performance boost.&lt;/li&gt;
&lt;li&gt;Public demo in AppStore :)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;instead-of-conclusion&#34;&gt;Instead of conclusion&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m sure that the markerless AR has a great future. With this technology we can create impressive presentations and games with seamless fusion of the real and augmented worlds. You will no more require to print some kind of markers. Just imagine - any kind of object can be a door to world of the augmented reality!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>