<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
Computer Vision Talks</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/><link rel=alternate type=application/rss+xml href=/index.xml title="Computer Vision Talks"><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Computer Vision Talks"><meta name=twitter:description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><meta property="og:title" content="Computer Vision Talks"><meta property="og:description" content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><meta property="og:type" content="website"><meta property="og:url" content="https://computer-vision-talks.com/"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Computer Vision Talks","url":"https:\/\/computer-vision-talks.com\/","description":"A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.","thumbnailUrl":"https:\/\/computer-vision-talks.com\/","license":""}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><h1 class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></h1><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a class=nav__link--active href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2011-02-04-markerless-augmented-reality-on-iphone/>MARKERLESS AUGMENTED REALITY ON IPHONE</a></h3><p>Hello everyone! Today i want to share my results in research of markerless augmented reality. The main idea - do fast and quality AR without those damn markers and give the ability to use real object as a target. Markerless augmented reality is very similar to marker-based systems like ARToolkit with one major difference - such technology use real object as a target for augmentation. It can be almost any kind of objects - photos, logos, beer bottle or Cola can.</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Fri, Feb 4, 2011</span>
<span><a class=tag href=/tags/opencv/>opencv</a><a class=tag href=/tags/iphone/>iphone</a><a class=tag href=/tags/ar/>ar</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2011-01-28-comparison-of-feature-descriptors/>COMPARISON OF FEATURE DESCRIPTORS</a></h3><p>Hello everyone! Today, we have very interesting topic! We will inspect different feature descriptor extractors. From this post you will know how robust is SURF, which disadvantages has BRIEF descriptor and how many times LAZY descriptor is faster than SURF. PS: I will be really appreciate if you point me to good implementations (C/C++) of RIFF, PCA SIFT, GLOH, LESH descriptors. I will include them in test suite. So, today our guinea pigs are:</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Fri, Jan 28, 2011</span>
<span><a class=tag href=/tags/opencv/>opencv</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2011-01-15-feature-descriptors-a-new-approach/>FEATURE DESCRIPTORS: A NEW APPROACH</a></h3><p>Last year I was tightly connected with image processing and feature tracking/matching. For my needs I’ve used SURF and later RIFF descriptors. Both of them have strong advantages and but… SURF descriptor robustness are compensated by it’s computational cost. RIFF descriptor extracts much faster but not robust enough for my needs. My needs are very simple – doing markerless AR on mobile phone. So, we (me and two other co-authors) decided to develop our own descriptor.</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Sat, Jan 15, 2011</span>
<span><a class=tag href=/tags/opencv/>opencv</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2011-01-12-using-opencv-in-objective-c-code/>USING OPENCV IN OBJECTIVE-C CODE</a></h3><p>After publishing Building OpenCV for iOS article many of readers asked me how to use OpenCV within ObjectiveC code, because they encountered compilation errors. In this post I’ll show you how to use OpenCV and ObjectiveC to make some image processing.
In this post I’ll use GLImageProcessing sample demo from Apple. Also you will need precompiled OpenCV for iPhone. How to make it read here. I’ve copied all OpenCV stuff to “opencv” folder into the GLImageProcessing.</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Wed, Jan 12, 2011</span>
<span><a class=tag href=/tags/opencv/>opencv</a><a class=tag href=/tags/xcode/>xcode</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2011-01-04-comparison-of-the-opencv-feature-detection-algorithms/>COMPARISON OF THE OPENCV’S FEATURE DETECTION ALGORITHMS</a></h3><p>Introduction
“In computer vision and image processing the concept of feature detection refers to methods that aim at computing abstractions of image information and making local decisions at every image point whether there is an image feature of a given type at that point or not. The resulting features will be subsets of the image domain, often in the form of isolated points, continuous curves or connected regions.”
Wikipedia</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Tue, Jan 4, 2011</span>
<span><a class=tag href=/tags/opencv/>opencv</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/2010-12-30-building-opencv-for-ios/>BUILDING OPENCV FOR IOS</a></h3><p>OpenCV (Open Source Computer Vision) is a library of programming functions for real time computer vision. This library has a huge number of algorithms.OpenCV supports Windows and Linux platforms (and Android starting from 2.2 version). But, unfortunately, there is no official iOS platform support for this moment. In this post i will show you that can build OpenCV for this platform and run it on your iPhone or iPad.
Software you’ll need XCode (Developer profile to be able debug on device) CMake Fresh OpenCV SVN command line tool or any GUI SVN client Getting the new version of OpenCV is pretty easy - just check out them from public svn repository:</p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Fri, Dec 17, 2010</span>
<span><a class=tag href=/tags/opencv/>opencv</a><a class=tag href=/tags/xcode/>xcode</a></span></div></div><div class="post
animated fadeInDown"><div class=post__content><h3><a href=/post/opencv-rocks-1/></a></h3><p></p></div><div class=post__footer><em class="fas fa-calendar-day"></em>
<span class=post__footer-date>Mon, Jan 1, 0001</span></div></div><div class=pagination><ul class=pagination__list><li class=pagination__list-item><a class=page-link href=/page/6/><i class="fa fa-angle-left" aria-label=Previous></i></a></li><li class=pagination__list-item><a class=page-link href=/>1</a></li><span class="page-link dots">&mldr;</span><li class=pagination__list-item><a class=page-link href=/page/6/>6</a></li><li class=pagination__list-item><span class="page-link current">7</span></li></ul></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>