<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
A battle of three descriptors: SURF, FREAK and BRISK</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/post/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="A battle of three descriptors: SURF, FREAK and BRISK"><meta name=twitter:description content="I think developers and research guys who works with object recognition, image registration and other areas that uses keypoint extraction can find this post useful. Recently (from 2.4.2) a new feature descriptor algorithm was added to OpenCV library. FREAK descriptor is claimed to be superior to ORB and SURF descriptors, yet it&rsquo;s very fast (comparable to ORB). Also people in comments on my blog mentioned BRISK descriptor which is also new and more efficient than SURF."><meta property="og:title" content="A battle of three descriptors: SURF, FREAK and BRISK"><meta property="og:description" content="I think developers and research guys who works with object recognition, image registration and other areas that uses keypoint extraction can find this post useful. Recently (from 2.4.2) a new feature descriptor algorithm was added to OpenCV library. FREAK descriptor is claimed to be superior to ORB and SURF descriptors, yet it&rsquo;s very fast (comparable to ORB). Also people in comments on my blog mentioned BRISK descriptor which is also new and more efficient than SURF."><meta property="og:type" content="article"><meta property="og:url" content="https://computer-vision-talks.com/post/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk/"><meta property="article:section" content="post"><meta property="article:published_time" content="2012-08-18T00:00:00+00:00"><meta property="article:modified_time" content="2012-08-18T00:00:00+00:00"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"A battle of three descriptors: SURF, FREAK and BRISK","headline":"A battle of three descriptors: SURF, FREAK and BRISK","alternativeHeadline":"","description":"
      
        I think developers and research guys who works with object recognition, image registration and other areas that uses keypoint extraction can find this post useful. Recently (from 2.4.2) a new feature descriptor algorithm was added to OpenCV library. FREAK descriptor is claimed to be superior to ORB and SURF descriptors, yet it\u0026rsquo;s very fast (comparable to ORB). Also people in comments on my blog mentioned BRISK descriptor which is also new and more efficient than SURF.


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/computer-vision-talks.com\/post\/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk\/"},"author":{"@type":"Person","name":"Eugene Khvedchenya"},"creator":{"@type":"Person","name":"Eugene Khvedchenya"},"accountablePerson":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightHolder":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightYear":"2012","dateCreated":"2012-08-18T00:00:00.00Z","datePublished":"2012-08-18T00:00:00.00Z","dateModified":"2012-08-18T00:00:00.00Z","publisher":{"@type":"Organization","name":"Eugene Khvedchenya","url":"https://computer-vision-talks.com/","logo":{"@type":"ImageObject","url":"https:\/\/computer-vision-talks.com\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/computer-vision-talks.com\/post\/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk\/","wordCount":"819","genre":[],"keywords":["opencv","xcode","tutorials"]}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></div><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>A Battle of Three Descriptors: SURF, FREAK and BRISK</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Sat, Aug 18, 2012</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>4-minute read</span></li></ul><p>I think developers and research guys who works with object recognition, image registration and other areas that uses keypoint extraction can find this post useful. Recently (from 2.4.2) a new feature descriptor algorithm was added to OpenCV library. FREAK descriptor is claimed to be superior to ORB and SURF descriptors, yet it&rsquo;s very fast (comparable to ORB). Also people in comments on my blog mentioned BRISK descriptor which is also new and more efficient than SURF. Well, finally i find a time to compare them and publish my research results.</p><h2 id=introduction>Introduction</h2><p>This post will be very similar to <a href=http://computer-vision-talks.com/2011/08/feature-descriptor-comparison-report/ title="Feature descriptor comparison report">OpenCV comparison reports</a> i made in past. Although those reports were published years ago, they are still somewhat actual. For this test i decided to rewrite the whole testing framework from scratch. The source code will be available soon. But for now, let me explain what i did to find a best of three algorithms. What is main goal of converting image to descriptors? Move from pixel domain to more compact form of representation the same data. In addition we would like our representation be rotation and scale invariant (e.g representation remains the same or changes slightly when source image rotated or scaled). SURF, FREAK and BRISK descriptors claims they are rotation and scale invariant.</p><h2 id=transformations>Transformations</h2><p>Like in the OpenCV comparison report, test application works with test pattern image. And we have four basic transformations: rotation, scale, blur and brightness adjustment. Here how the rotation transformation class looks like:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImageRotationTransformation</span> <span class=o>:</span> <span class=k>public</span> <span class=n>ImageTransformation</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl><span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>ImageRotationTransformation</span><span class=p>(</span><span class=kt>float</span> <span class=n>startAngleInDeg</span><span class=p>,</span> <span class=kt>float</span> <span class=n>endAngleInDeg</span><span class=p>,</span> <span class=kt>float</span> <span class=n>step</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>Point2f</span> <span class=n>rotationCenterInUnitSpace</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>:</span> <span class=n>ImageTransformation</span><span class=p>(</span><span class=s>&#34;Rotation&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>,</span> <span class=n>m_startAngleInDeg</span><span class=p>(</span><span class=n>startAngleInDeg</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>,</span> <span class=n>m_endAngleInDeg</span><span class=p>(</span><span class=n>endAngleInDeg</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>,</span> <span class=n>m_step</span><span class=p>(</span><span class=n>step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>,</span> <span class=n>m_rotationCenterInUnitSpace</span><span class=p>(</span><span class=n>rotationCenterInUnitSpace</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// Fill the arguments
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>for</span> <span class=p>(</span><span class=kt>float</span> <span class=n>arg</span> <span class=o>=</span> <span class=n>startAngleInDeg</span><span class=p>;</span> <span class=n>arg</span> <span class=o>&lt;</span> <span class=o>=</span> <span class=n>endAngleInDeg</span><span class=p>;</span> <span class=n>arg</span> <span class=o>+=</span> <span class=n>step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>m_args</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>arg</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>virtual</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span> <span class=n>getX</span><span class=p>()</span> <span class=k>const</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>m_args</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>virtual</span> <span class=kt>void</span> <span class=nf>transform</span><span class=p>(</span><span class=kt>float</span> <span class=n>t</span><span class=p>,</span> <span class=k>const</span> <span class=n>cv</span><span class=o>::</span><span class=n>Mat</span><span class=o>&amp;</span> <span class=n>source</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>Mat</span><span class=o>&amp;</span> <span class=n>result</span><span class=p>)</span> <span class=k>const</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>cv</span><span class=o>::</span><span class=n>Point2f</span> <span class=n>center</span><span class=p>(</span><span class=n>source</span><span class=p>.</span><span class=n>cols</span> <span class=o>*</span> <span class=n>m_rotationCenterInUnitSpace</span><span class=p>.</span><span class=n>x</span><span class=p>,</span> <span class=n>source</span><span class=p>.</span><span class=n>cols</span> <span class=o>*</span> <span class=n>m_rotationCenterInUnitSpace</span><span class=p>.</span><span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>cv</span><span class=o>::</span><span class=n>Mat</span> <span class=n>rotationMat</span> <span class=o>=</span> <span class=n>cv</span><span class=o>::</span><span class=n>getRotationMatrix2D</span><span class=p>(</span><span class=n>center</span><span class=p>,</span> <span class=n>t</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>cv</span><span class=o>::</span><span class=n>warpAffine</span><span class=p>(</span><span class=n>source</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=n>rotationMat</span><span class=p>,</span> <span class=n>source</span><span class=p>.</span><span class=n>size</span><span class=p>());</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>m_startAngleInDeg</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>m_endAngleInDeg</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>m_step</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>::</span><span class=n>Point2f</span> <span class=n>m_rotationCenterInUnitSpace</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span> <span class=n>m_args</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><p>Other types of transformations looks similar. But it shows the idea.</p><h2 id=featurealgorithm>FeatureAlgorithm</h2><p>As you may know we need three components when dealing with descriptors:</p><ul><li>Feature detector - class derived from cv::FeatureDetector class that implements particular detection algorithm. For example, cv::SurfFeatureDetector implements detection algorithm described in SURF paper.</li><li>Descriptor extractor - class derived from cv::DescriptorExtractor. It computes descriptors from passed keypoints. cv::SurfDescriptorExtractor will computer SURF descriptors.</li><li>Descriptor matcher - An instance of cv::BFMatcher of cv::FlannBasedMatcher classes is used to match two sets of descriptors.
We store these three objects in FeatureAlgorithm class:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>class</span> <span class=nc>FeatureAlgorithm</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl><span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>FeatureAlgorithm</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>string</span> <span class=n>name</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>FeatureDetector</span><span class=o>*</span> <span class=n>d</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>DescriptorExtractor</span><span class=o>*</span> <span class=n>e</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>DescriptorMatcher</span><span class=o>*</span> <span class=n>m</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>string</span> <span class=n>name</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>bool</span> <span class=n>knMatchSupported</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>bool</span> <span class=nf>extractFeatures</span><span class=p>(</span><span class=k>const</span> <span class=n>cv</span><span class=o>::</span><span class=n>Mat</span><span class=o>&amp;</span> <span class=n>image</span><span class=p>,</span> <span class=n>Keypoints</span><span class=o>&amp;</span> <span class=n>kp</span><span class=p>,</span> <span class=n>Descriptors</span><span class=o>&amp;</span> <span class=n>desc</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>void</span> <span class=nf>matchFeatures</span><span class=p>(</span><span class=k>const</span> <span class=n>Descriptors</span><span class=o>&amp;</span> <span class=n>train</span><span class=p>,</span> <span class=k>const</span> <span class=n>Descriptors</span><span class=o>&amp;</span> <span class=n>query</span><span class=p>,</span> <span class=n>Matches</span><span class=o>&amp;</span> <span class=n>matches</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>void</span> <span class=nf>matchFeatures</span><span class=p>(</span><span class=k>const</span> <span class=n>Descriptors</span><span class=o>&amp;</span> <span class=n>train</span><span class=p>,</span> <span class=k>const</span> <span class=n>Descriptors</span><span class=o>&amp;</span> <span class=n>query</span><span class=p>,</span> <span class=kt>int</span> <span class=n>k</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&amp;</span> <span class=n>matches</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>::</span><span class=n>FeatureDetector</span><span class=o>*</span>     <span class=n>detector</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>::</span><span class=n>DescriptorExtractor</span><span class=o>*</span> <span class=n>extractor</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>::</span><span class=n>DescriptorMatcher</span><span class=o>*</span>   <span class=n>matcher</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><h2 id=test-routine>Test routine</h2><p>The main test function takes FeatureAlgorithm, Transformation and test image. As output we return list of matching statistics for each run. Here is a brief sequence:</p><ul><li>Convert input image to grayscale</li><li>Detect keypoints and extract descriptors from input grayscale image</li><li>Generate all transformed images using passed transformation algorithm</li><li>For each of the transformed image:<ul><li>Detect keypoints and extract descriptors</li><li>Match train descriptors and query</li><li>Split matches to inliers and outliers using homography estimation</li><li>Compute statistics (consumed time, total percent of matches, percent of correct matches, etc)
The main cycle is paralleled using OpenMP, on my Quad Core i5 it loads all cores for 100% while doing test. Feature Algoritms:</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>algorithms</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>FeatureAlgorithm</span><span class=p>(</span><span class=s>&#34;SURF/BRISK/BF&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>SurfFeatureDetector</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>BriskDescriptorExtractor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>BFMatcher</span><span class=p>(</span><span class=n>cv</span><span class=o>::</span><span class=n>NORM_HAMMING</span><span class=p>,</span> <span class=nb>true</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>algorithms</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>FeatureAlgorithm</span><span class=p>(</span><span class=s>&#34;SURF/FREAK/BF&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>SurfFeatureDetector</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>FREAK</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>BFMatcher</span><span class=p>(</span><span class=n>cv</span><span class=o>::</span><span class=n>NORM_HAMMING</span><span class=p>,</span> <span class=nb>true</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>algorithms</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>FeatureAlgorithm</span><span class=p>(</span><span class=s>&#34;SURF/SURF/BF&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>SurfFeatureDetector</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>SurfDescriptorExtractor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=k>new</span> <span class=n>cv</span><span class=o>::</span><span class=n>BFMatcher</span><span class=p>(</span><span class=n>cv</span><span class=o>::</span><span class=n>NORM_L2</span><span class=p>,</span> <span class=nb>true</span><span class=p>)));</span>
</span></span></code></pre></div><p>Image transformations:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>transformations</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=k>new</span> <span class=n>GaussianBlurTransform</span><span class=p>(</span><span class=mi>9</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=n>transformations</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=k>new</span> <span class=n>BrightnessImageTransform</span><span class=p>(</span><span class=o>-</span><span class=mi>127</span><span class=p>,</span> <span class=o>+</span><span class=mi>127</span><span class=p>,</span> <span class=mi>10</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=n>transformations</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=k>new</span> <span class=n>ImageRotationTransformation</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>360</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>cv</span><span class=o>::</span><span class=n>Point2f</span><span class=p>(</span><span class=mf>0.5f</span><span class=p>,</span><span class=mf>0.5f</span><span class=p>)));</span>
</span></span><span class=line><span class=cl><span class=n>transformations</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=k>new</span> <span class=n>ImageScalingTransformation</span><span class=p>(</span><span class=mf>0.25f</span><span class=p>,</span> <span class=mf>2.0f</span><span class=p>,</span> <span class=mf>0.1f</span><span class=p>));</span>
</span></span></code></pre></div><p> </p><h2 id=metrics>Metrics</h2><p>The following metrics are calculated:</p><ul><li><strong>Percent of matches</strong> - quotient of dividing matches count on the minimum of keypoints count on two frames in percents.</li><li><strong>Percent of correct matches</strong> - quotient of dividing correct matches count on total matches count in percents.</li><li><strong>Matching ratio</strong> - percent of matches * percent of correct matches.
In all charts i will use &ldquo;Matching ratio&rdquo; ( in percents) value for Y-axis.</li></ul><h2 id=statistics>Statistics</h2><p>After running all tests we collect statistics for each transformation and algorithm. The report table for particular transformation algorithm looks like this:</p><pre tabindex=0><code>Argument SURF/BRISK/BF    SURF/FREAK/BF    SURF/SURF/BF
       1           100          88.5965         82.6752
       2           100          86.9608         79.1689
       3           100          85.6069         70.6731
       4           100          85.0897         64.9057
       5           100          83.1528         59.4776
       6           100          85.1648         58.9763
       7           100          88.6447         59.3066
       8           100          94.9109         64.8019
       9           100          95.9707         69.1154
</code></pre><p>To make a graphic representation i used Google Spreadsheets to import CSV tables and generate charts. You can find this spreadsheet here: <a href="https://docs.google.com/spreadsheet/ccc?key=0AuBBvmQlA4pfdGtPRHM5alBkQUowZEVBNlFrZ1dIa0E#gid=2">OpenCV 2.4.9 Features Comparison Report</a>.</p><h2 id=results>Results</h2><p>![][3] ![][4]</p><p>[3]: chart_6.png (SURF vs FREAK vs BRISK descriptors comparison (rotation))
[4]: chart_6-1.png (SURF vs FREAK vs BRISK descriptors comparison (scale))</p></div><div class=post__footer><span><a class=tag href=/tags/opencv/>opencv</a><a class=tag href=/tags/xcode/>xcode</a><a class=tag href=/tags/tutorials/>tutorials</a></span></div><div id=comment><h2>comments</h2><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cvtalks.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>