<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
OpenCV Tutorial - Part 4</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/post/2012-07-07-opencv-tutorial-part-4/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="OpenCV Tutorial - Part 4"><meta name=twitter:description content="This is the fourth part of the OpenCV Tutorial. In this part the solution of the annoying iOS video capture orientation bug will be described. Of course that&rsquo;s not all. There are some new features - we will add processing of saved photos from your photo album. Also to introduce minor interface improvements and I&rsquo;ll show you how to disable unsupported API like video capture in your app and run in on iOS Simulator."><meta property="og:title" content="OpenCV Tutorial - Part 4"><meta property="og:description" content="This is the fourth part of the OpenCV Tutorial. In this part the solution of the annoying iOS video capture orientation bug will be described. Of course that&rsquo;s not all. There are some new features - we will add processing of saved photos from your photo album. Also to introduce minor interface improvements and I&rsquo;ll show you how to disable unsupported API like video capture in your app and run in on iOS Simulator."><meta property="og:type" content="article"><meta property="og:url" content="https://computer-vision-talks.com/post/2012-07-07-opencv-tutorial-part-4/"><meta property="article:section" content="post"><meta property="article:published_time" content="2012-07-07T00:00:00+00:00"><meta property="article:modified_time" content="2012-07-07T00:00:00+00:00"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"OpenCV Tutorial - Part 4","headline":"OpenCV Tutorial - Part 4","alternativeHeadline":"","description":"
      
        This is the fourth part of the OpenCV Tutorial. In this part the solution of the annoying iOS video capture orientation bug will be described. Of course that\u0026rsquo;s not all. There are some new features - we will add processing of saved photos from your photo album. Also to introduce minor interface improvements and I\u0026rsquo;ll show you how to disable unsupported API like video capture in your app and run in on iOS Simulator.


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/computer-vision-talks.com\/post\/2012-07-07-opencv-tutorial-part-4\/"},"author":{"@type":"Person","name":"Eugene Khvedchenya"},"creator":{"@type":"Person","name":"Eugene Khvedchenya"},"accountablePerson":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightHolder":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightYear":"2012","dateCreated":"2012-07-07T00:00:00.00Z","datePublished":"2012-07-07T00:00:00.00Z","dateModified":"2012-07-07T00:00:00.00Z","publisher":{"@type":"Organization","name":"Eugene Khvedchenya","url":"https://computer-vision-talks.com/","logo":{"@type":"ImageObject","url":"https:\/\/computer-vision-talks.com\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/computer-vision-talks.com\/post\/2012-07-07-opencv-tutorial-part-4\/","wordCount":"936","genre":[],"keywords":["opencv","xcode","tutorials"]}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></div><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>OpenCV Tutorial - Part 4</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Sat, Jul 7, 2012</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>5-minute read</span></li></ul><p>This is the fourth part of the OpenCV Tutorial. In this part the solution of the annoying iOS video capture orientation bug will be described. Of course that&rsquo;s not all. There are some new features - we will add processing of saved photos from your photo album. Also to introduce minor interface improvements and I&rsquo;ll show you how to disable unsupported API like video capture in your app and run in on iOS Simulator.</p><p></p><h2 id=startup-images>Startup images</h2><p>Â  First of all, i would like to say a great thanks for my friend who made nice startup images for this project. I&rsquo;m really loving them, good graphics make application looks like a pro. Thanks Eugene. By the way, if you looking for free-lance graphic designer - feel free to contact him anytime. So i got a bunch of startup images. With regards to iOS guidelines, to fulfill all possible cases you need 6 different images - two for iPhone (for old one and for retina display) and four for iPad family (in portrait and landscape orientation for both retina and non-retina displays). Assigning them to XCode project was a trivial task - just drag and drop them to project options:</p><p><img src=Screen-Shot-2012-07-07-at-10.56.47-AM.png alt title="OpenCV Tutorial icons"></p><h2 id=device-interface-and-video-orientation>Device, Interface and Video orientation</h2><p>In the part 3 we created video capture class that use AVFoundation to get raw data from camera capture input. To present our images we introduced GLESImageView class. The motivation was to have fast rendering of bitmaps. But we experienced a problem with video orientation. If we were using AVVideoCapturePreviewLayer then iOS API take care about video/device/interface orientation by itself. But since our choice to use low-level capture API it&rsquo;s our headache. Fortunately, we have to do only one thing - apply the correct rotation for our texture with image with regards to the interface orientation. There is a slight difference between device orientation and interface orientation. The device orientation refers to physical orientation of your device in the world, while interface orientation refers to orientation of UI controls on the screen. To get the current interface orientation you will need an instance of UIViewController object that holds our GLESImageView. We can access interface orientation like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-objectivec data-lang=objectivec><span class=line><span class=cl><span class=n>UIInterfaceOrientation</span> <span class=n>uiOrientation</span> <span class=o>=</span> <span class=p>[</span><span class=n>viewController</span> <span class=n>interfaceOrientation</span><span class=p>];</span>
</span></span></code></pre></div><p>To follow SRP we put orientation handling code inside to GLESImageView class. To access the parent view controller from any view you can use following snippet code that i found somewhere on stackoverflow.com: <strong>GLESImageView.mm</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-objectivec data-lang=objectivec><span class=line><span class=cl><span class=p>-</span> <span class=p>(</span><span class=n>UIViewController</span> <span class=o>*</span><span class=p>)</span><span class=nf>viewController</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>UIResponder</span> <span class=o>*</span><span class=n>responder</span> <span class=o>=</span> <span class=nb>self</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>while</span> <span class=p>(</span><span class=o>!</span><span class=p>[</span><span class=n>responder</span> <span class=nl>isKindOfClass</span><span class=p>:[</span><span class=n>UIViewController</span> <span class=k>class</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>responder</span> <span class=o>=</span> <span class=p>[</span><span class=n>responder</span> <span class=n>nextResponder</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>(</span><span class=nb>nil</span> <span class=o>==</span> <span class=n>responder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=p>(</span><span class=n>UIViewController</span> <span class=o>*</span><span class=p>)</span><span class=n>responder</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=camera-frame-orientation>Camera frame orientation</h2><p>There is another one kind of orientation - AVCaptureVideoOrientation type. This enum defines the physical orientation of the images captured with particular capture device. The video orientation differs for front and rear cameras. Here is a proof link - <a href=http://developer.apple.com/library/ios/#qa/qa1744/_index.html#//apple_ref/doc/uid/DTS40011134>Technical Q&A QA1744</a>.</p><blockquote><p>The iPod touch, iPhone 4 and iPad 2 front facing camera is mounted AVCaptureVideoOrientationLandscapeLeft, and the back-facing camera is mounted AVCaptureVideoOrientationLandscapeRight.</p></blockquote><p>Also i draw your attention that AVCaptureVideoDataOutput does not support setting video orientation using API:</p><blockquote><p>Currently, the capture outputs for a movie file (AVCaptureMovieFileOutput) and still image (AVCaptureStillImageOutput) support setting the orientation, but the data output for processing video frames (AVCaptureVideoDataOutput) does not.</p></blockquote><p>Well, it&rsquo;s not so bat, actually. To handle different orientation of rear and front camera we can use simple flip operation. This brings AVCaptureVideoOrientationLandscapeLeft to AVCaptureVideoOrientationLandscapeRight. We&rsquo;ll use this video orientation as a standard orientation: <strong>VideoSource.mm</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-objectivec data-lang=objectivec><span class=line><span class=cl><span class=p>-</span> <span class=p>(</span><span class=kt>void</span><span class=p>)</span><span class=nf>captureOutput:</span><span class=p>(</span><span class=n>AVCaptureOutput</span> <span class=o>*</span><span class=p>)</span><span class=nv>captureOutput</span> 
</span></span><span class=line><span class=cl><span class=nf>didOutputSampleBuffer:</span><span class=p>(</span><span class=n>CMSampleBufferRef</span><span class=p>)</span><span class=nv>sampleBuffer</span> 
</span></span><span class=line><span class=cl>       <span class=nf>fromConnection:</span><span class=p>(</span><span class=n>AVCaptureConnection</span> <span class=o>*</span><span class=p>)</span><span class=nv>connection</span> 
</span></span><span class=line><span class=cl><span class=p>{</span> 
</span></span><span class=line><span class=cl>  <span class=p>...</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>cv</span><span class=o>::</span><span class=n>Mat</span> <span class=n>frame</span><span class=p>(</span><span class=n>height</span><span class=p>,</span> <span class=n>width</span><span class=p>,</span> <span class=n>CV_8UC4</span><span class=p>,</span> <span class=p>(</span><span class=kt>void</span><span class=o>*</span><span class=p>)</span><span class=n>baseAddress</span><span class=p>,</span> <span class=n>stride</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>([</span><span class=nb>self</span> <span class=n>videoOrientation</span><span class=p>]</span> <span class=o>==</span> <span class=n>AVCaptureVideoOrientationLandscapeLeft</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>::</span><span class=n>flip</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>frame</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=p>...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>There is four possible interface orientations - Portrait, PortraitUpsideDown, LandscapeLeft, LandscapeRight. So we can define four sets of texture coordinates that does correct visualization of our bitmap. At every frame we choose right set of texture coordinates with regards to interface orientation. Here is a code that i use: <strong>GLESImageView.mm</strong></p><pre tabindex=0><code>- (void)drawFrame:(const cv::Mat&amp;) bgraFrame
{
  ...

  GLfloat * textureVertices;
  static GLfloat textureVerticesPortrait[] =
  {
    1, 1,   1, 0,
    0, 1,   0, 0
  };  

  static GLfloat textureVerticesPortraitUpsideDown[] =
  {
    0, 0,   0, 1,
    1, 0,   1, 1
  };

  static GLfloat textureVerticesLandscapeLeft[] =
  {
    1, 0,   0, 0,
    1, 1,   0, 1
  };  

  static GLfloat textureVerticesLandscapeRight[] =
  {
    0, 1,   1, 1,
    0, 0,   1, 0
  }; 

  switch (uiOrientation)
  {
    case UIInterfaceOrientationPortrait:
      textureVertices = textureVerticesPortrait;
      break;

    case UIInterfaceOrientationPortraitUpsideDown:
      textureVertices = textureVerticesPortraitUpsideDown;
      break;

    case UIInterfaceOrientationLandscapeLeft:
      textureVertices = textureVerticesLandscapeLeft;
      break;

    case UIInterfaceOrientationLandscapeRight:
    default:
      textureVertices = textureVerticesLandscapeRight;
      break;
  };
    ...
}
</code></pre><p>Using this we select correct texture coordinates. The rest of drawing code left without changes. Great, now it seems that video looks correct at every orientation. Cool! Let&rsquo;s move on.</p><h2 id=processing-saved-photos>Processing saved photos</h2><p>Although processing video frames in real-time is awesome by itself, i though that adding a possibility to process a saved picture is also worth to be implemented. All the more so it&rsquo;s easier to implement than video processing. As usual, we start from creating a new ImageViewController class. Our view will contains UIImageView control to present processed result on the View. Like the VideoViewController, our class also requires a SampleBase object and input image to process.</p><p><img src=Screen-Shot-2012-07-07-at-11.14.25-AM.png alt title="Edge detection of saved photo"></p><p>This is how it looks. Two buttons in the top right corner is action buttons - the &ldquo;Save&rdquo; button puts a processed image to a saved photos album, the second button with camera picture - allows you to select another one image for processing.</p><p><strong>ImageViewController.h</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-objectivec data-lang=objectivec><span class=line><span class=cl><span class=k>@interface</span> <span class=nc>ImageViewController</span> : <span class=nc>UIViewController</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>-</span> <span class=p>(</span><span class=kt>void</span><span class=p>)</span> <span class=nf>setSample:</span><span class=p>(</span><span class=n>SampleBase</span><span class=o>*</span><span class=p>)</span> <span class=nv>sample</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>-</span> <span class=p>(</span><span class=kt>void</span><span class=p>)</span> <span class=nf>setImage:</span><span class=p>(</span><span class=n>UIImage</span><span class=o>*</span><span class=p>)</span> <span class=nv>image</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>@property</span> <span class=p>(</span><span class=k>weak</span><span class=p>,</span> <span class=k>nonatomic</span><span class=p>)</span> <span class=kt>IBOutlet</span> <span class=n>UIImageView</span> <span class=o>*</span><span class=n>imageView</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>@end</span>
</span></span></code></pre></div><p><strong>ImageViewController.mm</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-objectivec data-lang=objectivec><span class=line><span class=cl><span class=p>-</span> <span class=p>(</span><span class=kt>void</span><span class=p>)</span><span class=nf>viewDidLoad</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=p>[</span><span class=nb>super</span> <span class=n>viewDidLoad</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=c1>// Do any additional setup after loading the view.
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nb>self</span><span class=p>.</span><span class=n>navigationItem</span><span class=p>.</span><span class=n>rightBarButtonItems</span> <span class=o>=</span> <span class=p>[</span><span class=n>NSArray</span> <span class=nl>arrayWithObjects</span><span class=p>:</span>
</span></span></code></pre></div></div><div class=post__footer><span><a class=tag href=/tags/opencv/>opencv</a><a class=tag href=/tags/xcode/>xcode</a><a class=tag href=/tags/tutorials/>tutorials</a></span></div><div id=comment><h2>comments</h2><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cvtalks.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>