<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2"><meta name=twitter:description content="This is a second part of &ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital&rdquo; class.
In optional taks for Week 2 we were asked to test various predictors for JPEG-LS compression algorithm. In this post i want to share my results and discuss how we can achieve better prediction rate. Compare prediction algorithms for loseless image compression Problem statement
 Compute the histogram of a given image and of its prediction errors."><meta property="og:title" content="Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2"><meta property="og:description" content="This is a second part of &ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital&rdquo; class.
In optional taks for Week 2 we were asked to test various predictors for JPEG-LS compression algorithm. In this post i want to share my results and discuss how we can achieve better prediction rate. Compare prediction algorithms for loseless image compression Problem statement
 Compute the histogram of a given image and of its prediction errors."><meta property="og:type" content="article"><meta property="og:url" content="https://computer-vision-talks.com/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2/"><meta property="article:section" content="post"><meta property="article:published_time" content="2013-02-05T00:00:00+00:00"><meta property="article:modified_time" content="2013-02-05T00:00:00+00:00"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2","headline":"Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2","alternativeHeadline":"","description":"
      
        This is a second part of \u0026ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital\u0026rdquo; class.\nIn optional taks for Week 2 we were asked to test various predictors for JPEG-LS compression algorithm. In this post i want to share my results and discuss how we can achieve better prediction rate. Compare prediction algorithms for loseless image compression Problem statement\n Compute the histogram of a given image and of its prediction errors.


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/computer-vision-talks.com\/post\/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2\/"},"author":{"@type":"Person","name":"Eugene Khvedchenya"},"creator":{"@type":"Person","name":"Eugene Khvedchenya"},"accountablePerson":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightHolder":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightYear":"2013","dateCreated":"2013-02-05T00:00:00.00Z","datePublished":"2013-02-05T00:00:00.00Z","dateModified":"2013-02-05T00:00:00.00Z","publisher":{"@type":"Organization","name":"Eugene Khvedchenya","url":"https://computer-vision-talks.com/","logo":{"@type":"ImageObject","url":"https:\/\/computer-vision-talks.com\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/computer-vision-talks.com\/post\/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2\/","wordCount":"778","genre":[],"keywords":["coursera"]}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></div><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Image and Video Processing: From Mars to Hollywood With a Stop at the Hospital - Week 2</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Tue, Feb 5, 2013</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>4-minute read</span></li></ul><p>This is a second part of <a href=https://www.coursera.org/course/images>&ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital&rdquo;</a> class.</p><p>In optional taks for Week 2 we were asked to test various predictors for JPEG-LS compression algorithm. In this post i want to share my results and discuss how we can achieve better prediction rate.</p><h1 id=compare-prediction-algorithms-for-loseless-image-compression>Compare prediction algorithms for loseless image compression</h1><p><strong>Problem statement</strong></p><blockquote><p>Compute the histogram of a given image and of its prediction errors. If the pixel being processed is at coordinate (0,0), consider predicting based on just the pixel at (-1,0); predicting based on just the pixel at (0,1); predicting based on the average of the pixels at (-1,0), (-1,1), and (0,1). Compute the entropy for each one of the predictors in the previous exercise. Which predictor will compress better?</p></blockquote><p><strong>A very, very little theory</strong> So, first of all, JPEG-LS is a lose-less image compression algorithm. It uses variable-length coding (Huffman coding in particular) to minimize the amount of data needed to represent our image. So the idea behind this to predict the next pixel values using values of previous pixels and encode this error instead of pixels itself. So if we guess a lot, the distribution of the error would be non-uniform with a peak in near-zero area. So Huffan coding algorithm will be able reduce the code length.</p><h1 id=solution>Solution</h1><p>Based on the entropy of the input image we can describe prediction rate as follows: $$R=H_s / H_e$$, where $$H_s$$ is the entropy of the input image, and $$H_e$$ - is the entropy of the prediction error.</p><p>So, for my tests i wrote a simple OpenCV program that contains predictors test. You can find the full source code here: <strong><a href=http://pastebin.com/zWz9vaD7>http://pastebin.com/zWz9vaD7</a></strong>.</p><p>For all the tests i used well-known lena image:</p><p><img src=lena.jpg alt=lena.jpg></p><p>Which has following parameters of the gray-value representation:</p><blockquote><p>Std.Dev. 731.663 Entropy: 5.16456</p></blockquote><p>Here i&rsquo;m gonna describe only result of predictors. So we start from trivial predictors that use value of the previous pixel:</p><pre><code>int predict_by_previous_pixel_in_row(const cv::Mat_&amp; img, int row, int col)
{
    if (col &gt; 0)
        return img(row, col - 1);
    return 0;
}

int predict_by_previous_pixel_in_col(const cv::Mat_&amp; img, int row, int col)
{
    if (row &gt; 0)
        return img(row - 1, col);
    return 0;
}
</code></pre><p>These two predictors give us fair enough prediction rate of ~1.47:</p><blockquote><p>predict_by_previous_pixel_in_row: Std.Dev. 3322.94 Entropy: 3.50525</p><p>predict_by_previous_pixel_in_col: Std.Dev. 3940.22 Entropy: 3.20661</p></blockquote><p>Then i tried a predictor based on average value of two previous consecutive pixels:</p><pre><code>int predict_by_2prev_pixels_in_row(const cv::Mat_&amp; img, int row, int col)
{
    if (col &gt; 1)
        return ((int)img(row, col - 2) + (int)img(row, col - 1)) / 2;
    else
        return 0;
}
</code></pre><p>Regarding to the benchmark, this prediction strategy is worth than previous.</p><blockquote><p>predict_by_2prev_pixels_in_row: Std.Dev. 2908.91 Entropy: 3.70031</p></blockquote><p>Intuitively it&rsquo;s correct the more pixels we use for prediction, the more precise it will be. And the less prediction error we achieve. The fourth predictor i&rsquo;ve implemented was neighbor averaging predictor:</p><pre><code>int predict_by_neighbors(const cv::Mat_&amp; img, int row, int col)
{
    if (col &gt; 0 &amp;&amp; row &gt; 0)
    {
        int a = img(row, col - 1);
        int b = img(row - 1, col - 1);
        int c = img(row - 1, col);
        int s = a + b + c;
        
        float m = s / 3.0f;
        return (int)m;
    }
    else
        return 0;
}
</code></pre><p>It predicts the value of the next pixel by averaging values of it&rsquo;s closest neighbors (top, left and top-left pixel). This predictor shows better results than <strong>predict_by_2prev_pixels_in_row</strong>, <strong>predict_by_previous_pixel_in_row</strong>, but for some reason it cannot beat <strong>predict_by_previous_pixel_in_col</strong> algorithm:</p><blockquote><p>predict_by_ neighbors: Std.Dev. 3511.97 Entropy: 3.3431</p></blockquote><p>Then i remembered as Guillermo mentioned that JPEG-LS uses some sort of edge-detection to do this. So i tried to calculate gradient in X and Y directions using neighbor pixel values and compute the prediction using it:</p><pre><code>int predict_by_gradient(const cv::Mat_&amp; img, int row, int col)
{
    if (col &gt; 0 &amp;&amp; row &gt; 0)
    {
        int a = img(row, col - 1);
        int b = img(row - 1, col - 1);
        int c = img(row - 1, col);
                
        int gx = a - b;
        int gy = c - b;

        return (int)(b + (gx + gy) / 2.0f);
    }
    else
    {
        return 0;
    }
}
</code></pre><p>Well, at this moment this algorithm demonstrate the best prediction rate:</p><blockquote><p>predict_by_gradient: Std.Dev. 3881.62 Entropy: 3.18335</p></blockquote><p>Can we increase even more? Yes! I think we should use 3x3 neighbor area based prediction for this. I&rsquo;m pretty sure i&rsquo;m reinventing the wheel, but i think it&rsquo;s very fun and useful to train the brain with puzzles like this :) So, does anyone wants to share their predictors? Let&rsquo;s do a small challenge!</p><p><strong>Useful information for OpenCV users</strong>. The source code of my benchmark you can find here: <a href=http://pastebin.com/zWz9vaD7>http://pastebin.com/zWz9vaD7</a>.</p></div><div class=post__footer><span><a class=tag href=/tags/coursera/>coursera</a></span></div><div id=comment><h2>comments</h2><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cvtalks.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>