<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tutorials on Computer Vision Talks</title>
    <link>/tags/tutorials/</link>
    <description>Recent content in tutorials on Computer Vision Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Apr 2015 00:00:00 +0000</lastBuildDate><atom:link href="/tags/tutorials/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introducing CloudCV bootstrap</title>
      <link>/post/introducing-cloudcv-bootstrap/</link>
      <pubDate>Tue, 14 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/introducing-cloudcv-bootstrap/</guid>
      <description>Here&amp;rsquo;s an open-source ready to use bootstrap project written in Node.js that lets you to quickly build a REST service to host your image processing and computer vision code in a cloud environment. Please welcome: cloudcv-bootstrap.
I made this project aside of CloudCV to keep it simple but functionaly. It is self-contained Node.js project that helps you to get quick results on building and deploying your first server-based image processing service.</description>
    </item>
    
    <item>
      <title>How to debug node.js addons in Visual Studio</title>
      <link>/post/how-to-debug-nodejs-addons-in-visual-studio/</link>
      <pubDate>Tue, 17 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-debug-nodejs-addons-in-visual-studio/</guid>
      <description>While working on CloudCV I encountered problems in node.js addon written in native code. For CloudCV I use node.js with C++ Addon to separate high-performance algorithms (C++) from high-level networking API which node provides.
In this tutorial I&amp;rsquo;m going to reveal best practices on debugging C++ Addons for Node.js (0.12) using Visual Studio 2013.
Continue reading if you want to read in details why this works.
This article is valid for Node.</description>
    </item>
    
    <item>
      <title>Tile-based image processing</title>
      <link>/post/tile-based-image-processing/</link>
      <pubDate>Thu, 04 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/tile-based-image-processing/</guid>
      <description>How would you design an algorithm to process 40Mpx image? 100Mpx? What about gigapixel-sized panorams? Obviously, it should differs from those that are intended for 640x480 images. Here I want to present you implementation of the very simple but powerful approach called &amp;ldquo;Tile-based image processing&amp;rdquo;. I will show you how to make this using OpenCV.
First, let&amp;rsquo;s define a few restrictions in order to simplify our implementation. In this tutorial I will consider a &amp;lsquo;pass-through&amp;rsquo; pipeline - when we apply some function to input image and give an output image of the same size as an output.</description>
    </item>
    
    <item>
      <title>Image processing in your browser - Unit Test automation</title>
      <link>/post/image-processing-in-your-browser-unit-test-automation/</link>
      <pubDate>Fri, 31 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/image-processing-in-your-browser-unit-test-automation/</guid>
      <description>JavaScript. Do you like debug JavaScript code? I hate it. Literally. What what if you have to? In this post I&amp;rsquo;m going to show you how to simplify your life by automating unit testing of the JavaScript code for the browser.
To get things more interesting - let&amp;rsquo;s automate unit-testing of the image processing library called JSFeat. JSFeat provides a JavaScript implementation of the basic image processing operations that let you to process images in your browser and build sophisticated algorithms.</description>
    </item>
    
    <item>
      <title>Argument checking for native addons for Node.js. Do it right!</title>
      <link>/post/how-to-convert-args-from-js-to-cpp/</link>
      <pubDate>Thu, 11 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-convert-args-from-js-to-cpp/</guid>
      <description>During development of CloudCV I came to the problem on converting v8::Arguments to native C++ data types in my Node.js native module. If you are new to C++ and Node.js, I suggest you to read how to write C++ modules for Node.js and connecting OpenCV and Node.js first.
Mapping V8 data types to native C++ equivalents is trivial, but somewhat wordy. One should take the argument at given index, check whether it is defined, then check it&amp;rsquo;s type and finally cast to C++ type.</description>
    </item>
    
    <item>
      <title>Mapping data from Eigen to OpenCV and back</title>
      <link>/post/mapping-eigen-to-opencv/</link>
      <pubDate>Sat, 16 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-eigen-to-opencv/</guid>
      <description>Eigen is a C++ template library for matrix and vector operations. It is highly optimized for numeric operations and support vectorization and use aligned memory allocators.
When it comes to matrix operations, Eigen is much faster than OpenCV. However, it can be situations when it is necessary to pass Eigen data to OpenCV functions.
In this post I will show how to map Eigen data to OpenCV with easy and efficient way.</description>
    </item>
    
    <item>
      <title>A good resource on image processing using Python</title>
      <link>/post/pyimagesearch.com/</link>
      <pubDate>Thu, 07 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/pyimagesearch.com/</guid>
      <description>Let me introduce you Adrian Rosebrock and his http://www.pyimagesearch.com/ website. It&amp;rsquo;s about computer vision and image processing using Python and OpenCV. Looks like there are more than one person that like to share programming experience via blogging :)
Here&amp;rsquo;s how Adrian position himself:
 This blog is dedicated to helping other programmers understand how image search engines work. While a lot of computer vision concepts are theoretical in nature, I’m a big fan of “learning by example”.</description>
    </item>
    
    <item>
      <title>Training Haar cascade in the cloud</title>
      <link>/post/cloud-haartaining/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-haartaining/</guid>
      <description>In this post I&amp;rsquo;ll show you how you can train cascade classifier with OpenCV very quickly even if you have low-end hardware using virtual machine in the cloud.
Why Clouds? Well, training a descriptor takes a lot of time. Depending on template size, number of samples and stages, it can take from several ours to a couple of days to train such cascade! Be prepared that during training stage your PC will likely be unusuable due to high RAM usage and CPU load.</description>
    </item>
    
    <item>
      <title>Using Travis-CI for continuous testing your projects</title>
      <link>/post/2014-02-23-using-travis-ci/</link>
      <pubDate>Sun, 23 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-02-23-using-travis-ci/</guid>
      <description>img.img-thumbnail.pull-left(src=&amp;ldquo;travis-logo.png&amp;rdquo;)
p | In this post i will show you how i implemented continuous integration and testing in my
a(href=&amp;ldquo;http://cloudcv.io&amp;rdquo;) CloudCV | project. Healthy unit tests and easy and continuous integration workflow is a must in any project goes beyound &amp;ldquo;Hello, world&amp;rdquo; application. | Today software is a mixture of technologies of all kind. Therefore it can break literally everywhere. Each integration point is a place of risk. | The CloudCV has a C++ backend that is using OpenCV library, it&amp;rsquo;s front-end is written in Node.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial Part 7</title>
      <link>/post/2012-10-22-opencv-tutorial-part-7/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-10-22-opencv-tutorial-part-7/</guid>
      <description>After a long delay i&amp;rsquo;m happy to resume posting OpenCV tutorials in my blog. In Part 7 i will present you a new way of generation of icons for samples. Also i&amp;rsquo;ll show how to use NEON and assembly language to speed-up cv::transform function twice! Also there are three new samples i have to say few words about each.
Interface improvements Default sample icons I think each sample has to have it&amp;rsquo;s own unique icon image.</description>
    </item>
    
    <item>
      <title>A battle of three descriptors: SURF, FREAK and BRISK</title>
      <link>/post/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk/</link>
      <pubDate>Sat, 18 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-08-18-a-battle-of-three-descriptors-surf-freak-and-brisk/</guid>
      <description>I think developers and research guys who works with object recognition, image registration and other areas that uses keypoint extraction can find this post useful. Recently (from 2.4.2) a new feature descriptor algorithm was added to OpenCV library. FREAK descriptor is claimed to be superior to ORB and SURF descriptors, yet it&amp;rsquo;s very fast (comparable to ORB). Also people in comments on my blog mentioned BRISK descriptor which is also new and more efficient than SURF.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 6</title>
      <link>/post/2012-07-22-opencv-tutorial-part-6/</link>
      <pubDate>Sun, 22 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-07-22-opencv-tutorial-part-6/</guid>
      <description>[toc] Hi folks! I’m glad to publish a sixth part of the OpenCV Tutorial cycle. In this post I will describe how to implement interesting non-photorealistic effect that makes image looks like a cartoon. It has numerous names: cartoon filter or simply “toon” also it known as rotoscoping. In addition we will refactor application interface and add tweeting feature to share your results across the web. According to the roadmap I promised to put the video recording module too, but due to lack of free time I decided to put it on hold for now.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 5</title>
      <link>/post/2012-07-14-opencv-tutorial-part-5/</link>
      <pubDate>Sat, 14 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-07-14-opencv-tutorial-part-5/</guid>
      <description>Hello readers! The fifth part of the OpenCV Tutorial is here! In this post we will add options pane for our samples. In the end of this chapter our application will receive options interface as shown on screenshot. But first, let me remind you (if you came here for the first time) what is happening here. The &amp;ldquo;OpenCV Tutorial&amp;rdquo; is a open-source project maintained by me (Eugene Khvedchenya). My goal - create a iPhone/iPad application to demonstrate various image processing algorithms of OpenCV library and how to use them in iOS applications.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 4</title>
      <link>/post/2012-07-07-opencv-tutorial-part-4/</link>
      <pubDate>Sat, 07 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-07-07-opencv-tutorial-part-4/</guid>
      <description>This is the fourth part of the OpenCV Tutorial. In this part the solution of the annoying iOS video capture orientation bug will be described. Of course that&amp;rsquo;s not all. There are some new features - we will add processing of saved photos from your photo album. Also to introduce minor interface improvements and I&amp;rsquo;ll show you how to disable unsupported API like video capture in your app and run in on iOS Simulator.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 3</title>
      <link>/post/2012-06-27-opencv-tutorial-part-3/</link>
      <pubDate>Wed, 27 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-06-27-opencv-tutorial-part-3/</guid>
      <description>In Part 1 and Part 2 we created base application for our &amp;ldquo;OpenCV Tutorial&amp;rdquo; application. In this part we add video source to process frames using our samples and present the result to user. As usual, you can find source code for this application at github.
Video capture in iOS At this moment (as far as i know) there OpenCV&amp;rsquo;s cv::VideoCapture does not support iOS platform. Therefore we have to use iOS AVFoundation API to setup video capture.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 2</title>
      <link>/post/2012-06-24-opencv-tutorial-part-2/</link>
      <pubDate>Sun, 24 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-06-24-opencv-tutorial-part-2/</guid>
      <description>In the previous step we created Master-Detail XCode project and linked OpenCV library to it. Also we defined a base interface for all samples. Today we&amp;rsquo;ll write some UI logic to integrate our samples into the application. One ring to rule them all Since we are going to store a lot of samples (i hope so), we have to store them somewhere. I think for our application the ideal place to save them is our application delegate class.</description>
    </item>
    
    <item>
      <title>OpenCV Tutorial - Part 1</title>
      <link>/post/2012-06-23-opencv-tutorial-part-1/</link>
      <pubDate>Sat, 23 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-06-23-opencv-tutorial-part-1/</guid>
      <description>As i recently mentioned, i decided to write a brand new OpenCV tutorial application for iPhone/iPad devies. This development is open-source and anyone can access it on https://github.com/BloodAxe/OpenCV-Tutorial repository page. Your help are welcome to write a UI for this app and help writing sample demonstration cases. Feel free to clone repository and make your contribution!
OpenCV Tutorial The application startup screen will present master-detail view as a list of available samples.</description>
    </item>
    
    <item>
      <title>Rewriting OpenCV sample project for iOS</title>
      <link>/post/2012-06-19-rewriting-opencv-sample-project-for-ios/</link>
      <pubDate>Tue, 19 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-06-19-rewriting-opencv-sample-project-for-ios/</guid>
      <description>A lot of changes been made since I posted a tutorial of using OpenCV library on iPhone/iPad devices. It was the time of iOS 4.x and OpenCV 2.1. The time to rewrite the whole sample project has come. With this post I announce that I going to update my sample project and I ask for your help. My idea is to write a project which will demonstrate use of several common computer vision algorithms.</description>
    </item>
    
    <item>
      <title>Building OpenCV for iPhone in one click</title>
      <link>/post/2011-02-25-building-opencv-for-iphone-in-one-click/</link>
      <pubDate>Fri, 25 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011-02-25-building-opencv-for-iphone-in-one-click/</guid>
      <description>My first post in this blog was about building OpenCV for iOS devices (iPhone, iPad, iPod and so on). But the build process that i used is not trivial at all. I received a lot of feedbacks and questions about building OpenCV, setting up XCode build environment. Today i made your life much easier. I have a gift - a build script, which will **build OpenCV **library for your iPhone, iPad, iPod or any other iOS based Apple device right in one click!</description>
    </item>
    
    <item>
      <title>Introduction to morphology operations on images</title>
      <link>/post/2011-02-16-introduction-to-morphology-operations-on-images/</link>
      <pubDate>Wed, 16 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011-02-16-introduction-to-morphology-operations-on-images/</guid>
      <description>A brief tutorial/intro to the mathematical morphology in image processing.
Basic Definitions The term morphology refers to the description of the properties of shape and structure of any objects. In the context of computer vision, this term refers to the description of the properties of shapes of areas on the image. Operations of mathematical morphology were originally defined as operations on sets, but it soon became clear that they are also useful in the processing tasks of the set of points in the two-dimensional space.</description>
    </item>
    
  </channel>
</rss>
