<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
Computer vision Digest - May 2014</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/post/2014-05-computer-vision-digest/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Computer vision Digest - May 2014"><meta name=twitter:description content="This is a first issue of monthly computer vision digest - a list things that you don&rsquo;t wanna miss, a list of what happened in computer vision in May 2014.
In this issue:
 Browser image processing - how fast is it? Object recognition using neural networks via JavaScript NASA shares it&rsquo;s own computer vision library Easy optimization of image processing pipelines using decoupling algorithms OpenCV Apparel Store  Browser image processing - how fast is it?"><meta property="og:title" content="Computer vision Digest - May 2014"><meta property="og:description" content="This is a first issue of monthly computer vision digest - a list things that you don&rsquo;t wanna miss, a list of what happened in computer vision in May 2014.
In this issue:
 Browser image processing - how fast is it? Object recognition using neural networks via JavaScript NASA shares it&rsquo;s own computer vision library Easy optimization of image processing pipelines using decoupling algorithms OpenCV Apparel Store  Browser image processing - how fast is it?"><meta property="og:type" content="article"><meta property="og:url" content="https://computer-vision-talks.com/post/2014-05-computer-vision-digest/"><meta property="article:section" content="post"><meta property="article:published_time" content="2014-05-30T00:00:00+00:00"><meta property="article:modified_time" content="2014-05-30T00:00:00+00:00"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"Computer vision Digest - May 2014","headline":"Computer vision Digest - May 2014","alternativeHeadline":"","description":"
      
        This is a first issue of monthly computer vision digest - a list things that you don\u0026rsquo;t wanna miss, a list of what happened in computer vision in May 2014.\nIn this issue:\n Browser image processing - how fast is it? Object recognition using neural networks via JavaScript NASA shares it\u0026rsquo;s own computer vision library Easy optimization of image processing pipelines using decoupling algorithms OpenCV Apparel Store  Browser image processing - how fast is it?


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/computer-vision-talks.com\/post\/2014-05-computer-vision-digest\/"},"author":{"@type":"Person","name":"Eugene Khvedchenya"},"creator":{"@type":"Person","name":"Eugene Khvedchenya"},"accountablePerson":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightHolder":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightYear":"2014","dateCreated":"2014-05-30T00:00:00.00Z","datePublished":"2014-05-30T00:00:00.00Z","dateModified":"2014-05-30T00:00:00.00Z","publisher":{"@type":"Organization","name":"Eugene Khvedchenya","url":"https://computer-vision-talks.com/","logo":{"@type":"ImageObject","url":"https:\/\/computer-vision-talks.com\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/computer-vision-talks.com\/post\/2014-05-computer-vision-digest\/","wordCount":"1722","genre":[],"keywords":["news","digest"]}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></div><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Computer Vision Digest - May 2014</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Fri, May 30, 2014</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>9-minute read</span></li></ul><p>This is a first issue of monthly computer vision digest - a list things that you don&rsquo;t wanna miss, a list of what happened
in computer vision in May 2014.</p><p>In this issue:</p><ul><li><a href=#1>Browser image processing - how fast is it?</a></li><li><a href=#2>Object recognition using neural networks via JavaScript</a></li><li><a href=#3>NASA shares it&rsquo;s own computer vision library</a></li><li><a href=#4>Easy optimization of image processing pipelines using decoupling algorithms</a></li><li><a href=#5>OpenCV Apparel Store</a></li></ul><p></p><h2 id=browser-image-processing---how-fast-is-it>Browser image processing - how fast is it?</h2><p>Real-time image processing gets more and more demanded and popular since computer power grows and now it&rsquo;s possible to decode video, apply additional filters in real-time to play HD video smoothly. On desktop platforms this is not a &ldquo;wow&rdquo; anymore. In contrast, in web we cannot brag such results. So, Russian-speaking readers can stop reading here and visit original article: <a href=http://habrahabr.ru/post/221619/>Оценка возможности постобработки видео в браузере</a>. For others I wrote a translation of this post in a free form with my 5 cents.</p><p>Strictly speaking there are two options at the moment: either we use JavaScripts (pure JS, Asm.js or SIMD.js) or apply WebGL to utilize GPU.</p><h3 id=javascript-way>JavaScript way</h3><p>The image processing in JavaScript using Canvas.getImageData is slow like hell. On 1080p frames, getting frame-buffer from canvas can take up to 30ms on the desktop.
Regardless of the JavaScript runtime performance, the limiting factor for large images is Canvas - at the moment it is not optimized for frequent read/write access.</p><p>This is not all bad news - JavaScript is slow regardless of Canvas. Simple 3x3 box blur needs approximately 400ms to process single image frame:</p><pre><code>function blur(source, width, height) {
    function blur_core(ptr, offset, stride) {
        return (ptr[offset - stride - 4] +
                ptr[offset - stride] +
                ptr[offset - stride + 4] +
                ptr[offset - 4] +
                ptr[offset] +
                ptr[offset + 4] +
                ptr[offset + stride - 4] +
                ptr[offset + stride] +
                ptr[offset + stride + 4]
                ) / 9;
    }

    var stride = width * 4;
    for (var y = 1; y &lt; (height - 1); ++y) {
        var offset = y * stride;
        for (var x = 1; x &lt; stride - 4; x += 4) {
            source[offset] = blur_core(source, offset, stride);
            source[offset + 1] = blur_core(source, offset + 1, stride);
            source[offset + 2] = blur_core(source, offset + 2, stride);
            offset += 4;
        }
    }
}  
</code></pre><h3 id=asmjs>asm.js</h3><p>This JavaScript subset from Mozilla pretends to be extraordinarily optimizable code. This sub-language effectively describes a safe virtual machine for memory-unsafe languages like C or C++. A combination of static and dynamic validation allows JavaScript engines to employ an ahead-of-time (AOT) optimizing compilation strategy for valid asm.js code.</p><p>Well, it&rsquo;s hard to say writing asm.js code is fun. Be prepared to write code like this:</p><pre><code>for (i = 1; (i | 0) &lt; (ntp | 0); i = (i | 0) + 1 | 0) {
    // tp[i] = 2 * tp[i - 1]
    tp[(i &lt;&lt; 3) &gt;&gt; 3] = +(+2 * tp[((i - 1) &lt;&lt; 3) &gt;&gt; 3]);
}  
</code></pre><p>Or this:</p><pre><code>function f(x, y) {
    // SECTION A: parameter type declarations
    x = x|0;      // int parameter
    y = +y;       // double parameter

    // SECTION B: function body
    log(x|0);     // call into FFI -- must force the sign
    log(y);       // call into FFI -- already know it's a double
    x = (x+3)|0;  // signed addition

    // SECTION C: unconditional return
    return ((((x+1)|0)&gt;&gt;&gt;0)/(x&gt;&gt;&gt;0))|0; // compound expression
}
</code></pre><p>And all you get for this hard to read code is 2x speed-up. Not impressed.</p><p><img src=macro4b.png alt="Asm.js performance"></p><h3 id=simdjs>SIMD.js</h3><p>This one works only in Firefox Nightly builds and Chrome, and utilize parallelism to deliver high performance within a constrained power budget. Through Single Instruction, Multiple Data (SIMD) instructions, processors exploit the fine-grained parallelism in applications by simultaneously processing the same operation on multiple data items, delivering major performance improvements at high power efficiency. SIMD is particularly applicable to common computations in image/audio/video processing including computer vision and perceptual computing.</p><p>This library promised up for 400% speedups using floating-point computing:</p><p><img src=simd_in_firefox-623x261.jpg alt="SIMD.js in Firefox"></p><p>The API looks much better:</p><p><img src=image003_0.png alt=API></p><p>Did I mention that SIMD.js was made by <a href=https://01.org/node/1495>Intel</a>?</p><h3 id=webgl>WebGL</h3><p>This is orthogonal to what we considered before. WebGL is an API to GPU, and native OpenGL driver. Initially it was intented to be used in 3G graphics and gaming, but no one can prevent you to utilize General Purpose GPU (GPGPU) for image processing. Unfortunately, you will have to write shaders in very limited GLSL shading language which lacks of many cool features that are present in CUDA or OpenCL. But still, it is much faster than CPU way.</p><h3 id=conclusion>Conclusion</h3><p>At this moment, the only reasonable technology you may want to consider for real-time image processing is WebGL. You can think about CPU image processing only if you need to process small images or there is no neeed to fit in real-time.</p><p></p><h2 id=object-recognition-using-neural-networks-via-javascript>Object recognition using neural networks via JavaScript</h2><p>It can take years to master neural networks. Researchers spend enormous amount of time and efforts to study them and train networks to make them remember, predict and learn.
Neural networks are good for object recognition purpose when you have a fixed set of objects you want to recognize. In this sense they are like Haar Cascades. In contrast, NN can distinguis between 1000 object categories, while Haar Cascade classifier used to detect a single kind of object that can vary (The most popular use of cascades - face detection).</p><p>To demonstrate you the potential of NN, here is one example from <a href=http://www.image-net.org/challenges/LSVRC/2012/results.html>Large Scale Visual Recognition Challenge 2012</a>:
The SuperVision team won the <em>first place</em> using deep convolutional neural network trained on raw RGB pixel values. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three globally-connected layers with a final 1000-way softmax.</p><p><strong>It was trained on two NVIDIA GPUs for about a week.</strong></p><p>This is the price NN users pay for quality. But it worth of it.</p><p>Recenty I came across the interesting project that offers you a read-to-use implementation of similar implementation of Krizhevsky architecture in form of SDK for iOS, Android and even JavaScript!</p><p>So, please welcome <a href=https://www.jetpac.com/developer>Deep Belief SDK</a>.</p><p></p><h2 id=nasa-shares-its-own-computer-vision-library>NASA shares it&rsquo;s own computer vision library</h2><p><img src=Cev_launch.jpg alt="NASA ASR"></p><p>The NASA Vision Workbench (VW) is a general purpose image processing and computer vision library developed by the Autonomous Systems and Robotics (ASR) Area in the Intelligent Systems Division at the NASA Ames Research Center. VW has been publicly released under the terms of the NASA Open Source Software Agreement.</p><p>The Vision Workbench was implemented in the C++ programming language and makes extensive use of C++ templates and generative programming techniques for conciseness of expression, efficiency of operation, and generalization of implementation.</p><p>I suggest for everyone who works in computer vision to look at the source code of this library. The design of this library is very unusual - you will not find a direct memory
access there. Instead, all algorithms uses iterators, locators and templates. This produce a clean and very self-explanatory code:</p><pre><code>template &lt;class SrcT, class DestT&gt;
void convolve_1d( SrcT const&amp; src, DestT const&amp; dest, std::vector&lt;KernelT&gt; const&amp; kernel ) const {
  typedef typename SrcT::pixel_accessor SrcAccessT;
  typedef typename DestT::pixel_accessor DestAccessT;
  typedef typename DestT::pixel_type DestPixelT;
  typedef typename CompoundChannelType&lt;DestPixelT&gt;::type channel_type;

  VW_ASSERT( src.planes() == dest.planes(), ArgumentErr() &lt;&lt; &quot;convolve_1d: Images should have the same number of planes&quot; );

  SrcAccessT splane = src.origin();
  DestAccessT dplane = dest.origin();
  for( int32 p=0; p&lt;dest.planes(); ++p ) {
    SrcAccessT srow = splane;
    DestAccessT drow = dplane;
    for( int32 y=0; y&lt;dest.rows(); ++y ) {
      SrcAccessT scol = srow;
      DestAccessT dcol = drow;
      for( int32 x=0; x&lt;dest.cols(); ++x ) {
        *dcol = channel_cast_clamp_if_int&lt;channel_type&gt;( correlate_1d_at_point( scol, kernel.rbegin(), kernel.size() ) );
        scol.next_col();
        dcol.next_col();
      }
      srow.next_row();
      drow.next_row();
    }
    splane.next_plane();
    dplane.next_plane();
  }
}
</code></pre><p>I recommend to take a look in this library to improve your language skills and have look on alternative approach how computer vision library can looks like.</p><p>Github: <a href=https://github.com/nasa/visionworkbench>nasa/visionworkbench</a>.</p><p></p><h2 id=easy-optimization-of-image-processing-pipelines-using-decoupling-algorithms>Easy optimization of image processing pipelines using decoupling algorithms</h2><p>Take a look on picture below. Which code you find easier to percept? Both produce identical results, they have equal speed. But which one is easier to read and understand?</p><p><img src=halide_vs_cpp.png alt></p><p>Very often I find myself thinking about how bored I am with tuning function with SSE, NEON or Assembly language. Real-time image processing requires you to count every millisecond, so sometimes you have to optimize slow functions, change a pipeline to &lsquo;fuse&rsquo; results or modify data flow to ensure better data locality. SIMD, GPGPU are good, not doubts. But they does not provide a final solution to fundamental problem - in my opinion, imperative approach limit the way you implement particular algorithm.</p><p>There is a great idea - to separate Algorithm from it&rsquo;s Implementation. Why this matters?</p><ul><li>Writing fast image processing pipelines is hard</li><li>C-parallelism + tiling + fusion are hard to write or automate</li><li>CUDA, OpenCL, shaders - data parallelism is easy, fusion is hard</li><li>BLAS, IPP, OpenCV, MKL - optimized kernels compose into inefficient pipelines (no fusion)</li></ul><p>Proposed solution: Decouple Algorithm from Schedule</p><p><em>Algorithm</em> defines <em>what</em> is computed.
<em>Schedule</em> defines <em>where</em> and <em>when</em> it&rsquo;s computed.</p><p>Such decoupling lets developers a to build pipelines easy by defining a pure functions that operates on data in easy and clean way. No need to worry on tiling, parallelism and fusion. From the other side it will let the compiler to generate fast code.</p><p>I want present you Halide - the image processing language that let&rsquo;s you to write highly efficient code with less headache. Just compare two implementations of</p><p>Here is an example written in Halide:</p><p><img src=halide-blur3x3.png alt></p><p>Even without experience with Halide, it is more or less clear what this code does. The Algorithm is separated from Schedule in very elegant way. During compilation stage,
Halide compiler will generate C++ code for particular platform.</p><h3 id=presentation-slides-on-halide-language>Presentation slides on Halide language:</h3><p>Original article: <a href=http://people.csail.mit.edu/jrk/halide12/>Decoupling algorithms from schedules for easy optimization of image processing pipelines</a>.</p><p></p><h2 id=opencv-apparel-store>OpenCV Apparel Store</h2><p>This is less technical topic for the end of this digest. If you feel ok to support OpenCV open-source library - this one is for you.
What about having a T-shirt or hoodie with OpenCV logo?</p><p><img src=l26503.jpg alt="OpenCV Hoodie">
<img src=lst30665.jpg alt="OpenCV Hoodie"></p><p>A nice way to say &ldquo;thanks&rdquo; to OpenCV team :)</p><p>Store webpage: <a href="http://fhstore.com/shopping/FHShop2.aspx?PON=74808&CON=75944&SCN=19&CN=76&ASN=&VSN=&AC=">OpenCV Apparel Store</a>.</p><h2 id=the-end>The End</h2><p>That&rsquo;s all folks! I hope you enjoyed this digest. Please, leave your and feedbacks in comments. Please let me know if you interested in getting this digest on regular basis!</p></div><div class=post__footer><span><a class=tag href=/tags/news/>news</a><a class=tag href=/tags/digest/>digest</a></span></div><div id=comment><h2>comments</h2><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cvtalks.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>