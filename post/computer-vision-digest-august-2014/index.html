<!doctype html><html dir=ltr lang=en data-theme class=html><head><title>Eugene Khvedchenya
|
Computer Vision Digest - August 2014</title><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Eugene Khvedchenya"><meta name=description content="A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books."><link rel=stylesheet href=/scss/main.min.b2e0cb07595e3519ab1193bb421914e06c0e26b0cc561fef23b3c6131d4d2ffa.css integrity="sha256-suDLB1leNRmrEZO7QhkU4GwOJrDMVh/vI7PGEx1NL/o=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.31b0a1f317f55c529a460897848c97436bb138b19c399b37de70d463a8bf6ed5.css integrity="sha256-MbCh8xf1XFKaRgiXhIyXQ2uxOLGcOZs33nDUY6i/btU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=canonical href=https://computer-vision-talks.com/post/computer-vision-digest-august-2014/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.560a26330d27ff44a44e83b53cd07a95d4230a65930d31c5c76a8d481e5b35bf.js integrity="sha256-VgomMw0n/0SkToO1PNB6ldQjCmWTDTHFx2qNSB5bNb8=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Computer Vision Digest - August 2014"><meta name=twitter:description content="Third computer vision digest. Your monthly portion of news in computer vision for August 2014.
In this issue:
 Free Photo Editing Software Lets You Manipulate Objects in 3D Real-Time Digital Makeup with Projection Mapping Video stabilization through 3D scene recovery Using OpenCV, Python and Template Matching to play “Where’s Waldo?” OpenCV 3.0 alpha is out  Previous issues:
 Computer Vision Digest (May 2014) Computer Vision Digest (June 2014)  How much Photoshop magic can you make with 2D photo?"><meta property="og:title" content="Computer Vision Digest - August 2014"><meta property="og:description" content="Third computer vision digest. Your monthly portion of news in computer vision for August 2014.
In this issue:
 Free Photo Editing Software Lets You Manipulate Objects in 3D Real-Time Digital Makeup with Projection Mapping Video stabilization through 3D scene recovery Using OpenCV, Python and Template Matching to play “Where’s Waldo?” OpenCV 3.0 alpha is out  Previous issues:
 Computer Vision Digest (May 2014) Computer Vision Digest (June 2014)  How much Photoshop magic can you make with 2D photo?"><meta property="og:type" content="article"><meta property="og:url" content="https://computer-vision-talks.com/post/computer-vision-digest-august-2014/"><meta property="article:section" content="post"><meta property="article:published_time" content="2014-08-30T00:00:00+00:00"><meta property="article:modified_time" content="2014-08-30T00:00:00+00:00"><meta property="og:site_name" content="Computer Vision Talks"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"Computer Vision Digest - August 2014","headline":"Computer Vision Digest - August 2014","alternativeHeadline":"","description":"
      
        Third computer vision digest. Your monthly portion of news in computer vision for August 2014.\nIn this issue:\n Free Photo Editing Software Lets You Manipulate Objects in 3D Real-Time Digital Makeup with Projection Mapping Video stabilization through 3D scene recovery Using OpenCV, Python and Template Matching to play “Where’s Waldo?” OpenCV 3.0 alpha is out  Previous issues:\n Computer Vision Digest (May 2014) Computer Vision Digest (June 2014)  How much Photoshop magic can you make with 2D photo?


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/computer-vision-talks.com\/post\/computer-vision-digest-august-2014\/"},"author":{"@type":"Person","name":"Eugene Khvedchenya"},"creator":{"@type":"Person","name":"Eugene Khvedchenya"},"accountablePerson":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightHolder":{"@type":"Person","name":"Eugene Khvedchenya"},"copyrightYear":"2014","dateCreated":"2014-08-30T00:00:00.00Z","datePublished":"2014-08-30T00:00:00.00Z","dateModified":"2014-08-30T00:00:00.00Z","publisher":{"@type":"Organization","name":"Eugene Khvedchenya","url":"https://computer-vision-talks.com/","logo":{"@type":"ImageObject","url":"https:\/\/computer-vision-talks.com\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/computer-vision-talks.com\/post\/computer-vision-digest-august-2014\/","wordCount":"1350","genre":[],"keywords":["news","digest"]}</script></head><body class="body theme--light"><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/4ECfkGJr_400x400.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Computer Vision Talks</a></div><div class=sidebar__introduction-description><p>A personal blog about Computer Vision, AI, Kaggle, Open-Source and research. You will never read this in books.</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://www.linkedin.com/in/cvtalks/ target=_blank rel=noopener aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/cvtalks target=_blank rel=noopener aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/BloodAxe target=_blank rel=noopener aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:ekhvedchenya@computer-vision-talks.com target=_blank rel=noopener aria-label=E-Mail title=E-Mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=/open-source title>Open-Source</a></li><li class=nav__list-item><a href=/challenges title>Wins</a></li><li class=nav__list-item><a href=/publications title>Publications</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Computer Vision Digest - August 2014</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Sat, Aug 30, 2014</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>7-minute read</span></li></ul><p>Third <a href=/tags/digest.html>computer vision digest</a>. Your monthly portion of news in computer vision for August 2014.</p><p>In this issue:</p><ul><li><a href=#1>Free Photo Editing Software Lets You Manipulate Objects in 3D</a></li><li><a href=#2>Real-Time Digital Makeup with Projection Mapping</a></li><li><a href=#3>Video stabilization through 3D scene recovery</a></li><li><a href=#4>Using OpenCV, Python and Template Matching to play “Where’s Waldo?”</a></li><li><a href=#5>OpenCV 3.0 alpha is out</a></li></ul><p>Previous issues:</p><ul><li><a href=/articles/2014-05-computer-vision-digest/>Computer Vision Digest (May 2014)</a></li><li><a href=/articles/2014-06-computer-vision-digest/>Computer Vision Digest (June 2014)</a></li></ul><p><img src=http://i.kinja-img.com/gawker-media/image/upload/s--CtQ_vCt9--/c_fit,fl_progressive,q_80,w_636/sbuewdyltzbjdmfjvgof.gif alt="Free Photo Editing Software Lets You Manipulate Objects in 3D"></p><p>How much Photoshop magic can you make with 2D photo? This software can do more! SIGGRAPH 2014 showed us a method that enables users to perform the full range of 3D manipulations, including scaling, rotation, translation, and nonrigid deformations, to an object in a photograph. Despite the fact it has limitations to use of stock 3D models set that are available for manipulation, it is great demonstration on how 2D and 3D can be combined together to bring image manipulation for the next level. I think Adobe is already buying these guys (and one girl).</p><p>The cool news, there are free demo, source code and publication paper that you can read:</p><ul><li><a href=http://www.cs.cmu.edu/~om3d/sourcecodeversions.html>Source code</a></li><li><a href=http://www.cs.cmu.edu/~om3d/agreement.html>OS X (Mavericks) Executable Code and Examples</a></li><li><a href=http://www.cs.cmu.edu/~om3d/papers/SIGGRAPH2014.pdf>Publication paper</a></li></ul><p>This is how state of the art technologies comes to real life. Well studied algorithms and a bit of tech = amazing results. Projection mapping in conjunction with real-time face tracking made possible a virtual make-up! No more words. Watch this:</p><p>A true beauty of augmented reality. Girls, you don&rsquo;t need to do a make-up for virtual date anymore :)</p><p><strong>So how did they made it?</strong></p><p>I assume this involves real-time frame tracker that outputs a face 3D model which is 99% tuned for particular person via offline training (Google: Active appearance model).
Have you noticed white dots on her face? These are special markers that are used to &ldquo;wire&rdquo; face 3D model to real one.</p><p>And then they take virtual makeup (A texture that mapped onto 3D face model) and deform it to match tracked model. A projector then maps virtual makeup onto actor.</p><p>Well done, OMOTE. This was great demonstration!</p><p>Source: <a href=http://www.augmentedrealitytrends.com/augmented-reality/projection-mapping.html>Real-Time Digital Makeup with Projection Mapping</a>.</p><p>This is not about Instagram :)</p><p>Microsoft Research showed more sophisticated video stabilization algorithms for making Hyperlapse video from the raw footage made with ordinary handheld camera.</p><p>Developers claim that their result impossible to achieve using alternative ways of stabilization. The method is based on the reconstruction of the 3D-scene, and then algorithm optimize &ldquo;movement&rdquo; of the camera along the route in order to avoid vibration, and combines the images pixel by pixel to smooth video sequence.</p><p>For example, the figure below shows this route (in black) and an optimized route, which is generated by the application to render the video (red).</p><p><img src=microsoft-hyperlapse-path-planning.jpg alt></p><p>The result is a so-called hyperlapse-video (named by analogy with the time-lapse, slow-motion filming).</p><p>Technicaly, the algorithm builds Hyperlapse video in three steps:</p><ol><li><strong>Recover 3D scene</strong> from the camera motion. This is well-known task called &ldquo;Structure from Motion&rdquo; and one camera is enough to recover 3D environment (Google: Monocular SLAM).</li><li><strong>Optimize route</strong> (or Path Planning) - on previous step algorithm recover camera route that include shakes, vibration and occasion motions that should be exludede from result Hyperlapse. The goal of this step is to make smooth and stable transition from frame to frame by optimizing route.</li><li>** Render Hyperlapse**. This step doing reverse things - it sample pixel values from all visible frames that were used to reconstruct given pose and pick best ones that produce really nice stiched image. Having 3D environment has a great advantage when algorithm has to &ldquo;inpaint&rdquo; missing reginos - it can sample pixels from the other frames because system reallly knows what is the 3D structure around.</li></ol><p>You can read publication of this approach from the Microsoft Research: <a href=http://research.microsoft.com/en-us/um/redmond/projects/hyperlapse/paper/hyperlapse.pdf>First-person Hyper-lapse Videos</a>.</p><p><img src=puzzle_small.jpg alt></p><p>This <a href=http://machinelearningmastery.com/using-opencv-python-and-template-matching-to-play-wheres-waldo/>article</a> is for beginners who start learning computer vision. This tutorial describe very basic, but still powerful technique called template matching for object detection. “Where’s Waldo?” probably the best candidate for template matching demonstration - the task is very clear and this article contain step by step solution on detecting Waldo using computer vision.</p><p>Using Python it&rsquo;s really simple to write your first algorithm:</p><pre><code>puzzle = cv2.imread(args[&quot;puzzle&quot;])
waldo = cv2.imread(args[&quot;waldo&quot;])
result = cv2.matchTemplate(puzzle, waldo, cv2.TM_CCOEFF)
(_, _, minLoc, maxLoc) = cv2.minMaxLoc(result)
# the puzzle image
topLeft = maxLoc
botRight = (topLeft[0] + waldoWidth, topLeft[1] + waldoHeight)
roi = puzzle[topLeft[1]:botRight[1], topLeft[0]:botRight[0]]

# construct a darkened transparent 'layer' to darken everything
# in the puzzle except for waldo
mask = np.zeros(puzzle.shape, dtype = &quot;uint8&quot;)
puzzle = cv2.addWeighted(puzzle, 0.25, mask, 0.75, 0)

# put the original waldo back in the image so that he is
# 'brighter' than the rest of the image
puzzle[topLeft[1]:botRight[1], topLeft[0]:botRight[0]] = roi
 
# display the images
cv2.imshow(&quot;Puzzle&quot;, imutils.resize(puzzle, height = 650))
cv2.imshow(&quot;Waldo&quot;, waldo)
cv2.waitKey(0)
</code></pre><p><img src=puzzle_found_waldo1.jpg alt></p><p>Original article can be found here: <a href=http://machinelearningmastery.com/using-opencv-python-and-template-matching-to-play-wheres-waldo/>Using OpenCV, Python and Template Matching to play “Where’s Waldo?”</a>.</p><p></p><h2 id=opencv-30-alpha-is-out>OpenCV 3.0 alpha is out</h2><p>That&rsquo;s it. OpenCV grows and going to college. 5 years has passed since OpenCV 2.0, which brought us a new C++ API, GPU-accelerated algorithms, iOS and Android platforms support, CUDA and OpenCL, Python and Java bindings.</p><p><strong>Modular project architecture</strong>. Since very beginning OpenCV was one solid project, built and shipped as a whole, and that was good strategy for many years. However, with constantly growing functionality, including bleeding-edge algorithms published a few minutes before a pull request has been submitted to our repository, and increasing number of contributors (thank you all very much, guys!) we came to the same conclusion and decision as many other big project – the solid model does not work anymore.</p><p><strong>T-API</strong>. GPU acceleration made really easy with brand new T-API (“transparent API”) made in cooperation with Intel and AMD. <a href=https://github.com/Itseez/opencv/tree/master/samples/tapi>T-API Samples</a>.</p><p><strong>OpenCV now linked with IPP by default</strong>. Intel corporation gave OpenCV another exciting present. A subset of Intel Integrated Performance Primitives (IPP) is linked by default into OpenCV and is available at <strong>no charge for all our users</strong>. And that includes the license to redistribute applications that use IPP-accelerated OpenCV. As you may see, for quite a few image processing functions we achieved very noticeable speedup with IPP (where IPP is compared with OpenCV built with all possible optimizations turned on):</p><p><img src=ocv3_ipp_speedup.jpg alt="IPP in OpenCV 3.0"></p><p>Last but not least, OpenCV 3.0 brings a lot of <strong>new functionality</strong>, such as:</p><ul><li>Text detection and recognition by Lluis Gomez and Stefano Fabri</li><li>HDR by Fedor Morozov and Alexander Shishkov</li><li>KAZE/A-KAZE by Eugene Khvedchenya, the algorithm author Pablo Alcantarilla and some improvements by F. Morozov.</li><li>Smart segmentation and edge-aware filters by Vitaly Lyudvichenko, Yuri Gitman, Alexander Shishkov and Alexander Mordvintsev</li><li>Car detection using Waldboost, ACF by Vlad Shakhuro and Nikita Manovich</li><li>TLD tracker and several common-use optimization algorithms by Alex Leontiev</li><li>Matlab bindings by Hilton Bristow, with support from Mathworks.</li><li>Greatly extended Python bindings, including Python 3 support, and several OpenCV+Python tutorials by Alexander Mordvintsev, Abid Rahman and others.</li><li>3D Visualization using VTK by Ozan Tonkal and Anatoly Baksheev.</li><li>RGBD module by Vincent Rabaud</li><li>Line Segment Detector by Daniel Angelov</li><li>Many useful Computational Photography algorithms by Siddharth Kherada</li><li>Shape descriptors, matching and morphing shapes (shape module) by Juan Manuel Perez Rua and Ilya Lysenkov</li><li>Long-term tracking + saliency-based improvements (tracking module) by Antonella Cascitelli and Francesco Puja</li><li>Another good pose estimation algorithm and the tutorial on pose estimation by Edgar Riba and Alexander Shishkov</li><li>Line descriptors and matchers by Biagio Montesano and Manuele Tamburanno</li><li>Myriads of improvements in various parts of the library by Steven Puttemans; thank you a lot, Steven!</li><li>Several NEON optimizations by Adrian Stratulat, Cody Rigney, Alexander Petrikov, Yury Gorbachev and others.</li><li>Fast foreach loop over cv::Mat by Kazuki Matsuda</li><li>Image alignment (ECC algorithm) by Georgios Evangelidis</li><li>GDAL image support by Marvin Smith</li><li>RGBD module by Vincent Rabaud</li><li>Fisheye camera model by Ilya Krylov</li><li>OSX framework build script by Eugene Khvedchenya</li><li>Multiple FLANN improvements by Pierre-Emmanuel Viel</li><li>Improved WinRT support by Gregory Morse</li><li>Latent SVM Cascade by Evgeniy Kozhinov and NNSU team (awaiting integration)</li><li>Logistic regression by Rahul Kavi</li><li>Five-point pose estimation algorithm by Bo Li</li></ul><p>The 3.0-alpha package can be downloaded:</p><ul><li><a href=https://github.com/Itseez/opencv/tree/3.0.0-alpha>Source code as .zip package directly from github</a></li><li><a href=https://sourceforge.net/projects/opencvlibrary/files/opencv-win/3.0.0-alpha/>Precompiled, Windows</a></li><li><a href=https://sourceforge.net/projects/opencvlibrary/files/opencv-ios/3.0.0-alpha/>Precompiled, iOS</a></li></ul></div><div class=post__footer><span><a class=tag href=/tags/news/>news</a><a class=tag href=/tags/digest/>digest</a></span></div><div id=comment><h2>comments</h2><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cvtalks.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Eugene Khvedchenya
2022</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.9c062c557275acbaba71f0c7cd4024da3e3cc825d248bc4b2130811b0965330b.js integrity="sha256-nAYsVXJ1rLq6cfDHzUAk2j48yCXSSLxLITCBGwllMws=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-10687369-5","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>